out <- prepDocuments(myprocess$documents, myprocess$vocab, myprocess$meta,lower.thresh = 500)
model1_searchK <- searchK(out$documents, out$vocab, K = c(4:30),
prevalence = ~s(pub.year),
data = out$meta, init.type="Spectral"
,cores=detectCores()-4)
saveRDS(model1_searchK,'model1_searchK.rds')
plot(model1_searchK)
model1_res <- model1_searchK$results
model1_res <- unnest(model1_res,c(K,exclus,semcoh))
ggplot(model1_res, aes(x = semcoh, y = exclus, label = K)) +
geom_point() +
geom_text(vjust = -0.5, hjust = 0.5) +
labs(x = "Semantic Coherence", y = "Exclusivity", title = "Semantic Coherence vs Exclusivity") +
theme_minimal()
plot(model1_searchK)
model1_res <- model1_searchK$results
model1_res <- unnest(model1_res,c(K,exclus,semcoh))
ggplot(model1_res, aes(x = semcoh, y = exclus, label = K)) +
geom_point() +
geom_text(vjust = -0.5, hjust = 0.5) +
labs(x = "Semantic Coherence", y = "Exclusivity", title = "Semantic Coherence vs Exclusivity") +
theme_minimal()
model1_res <- model1_searchK$results
model1_res <- unnest(model1_res,c(K,exclus,semcoh))
ggplot(model1_res, aes(x = semcoh, y = exclus, label = K)) +
geom_point() +
geom_text(vjust = -0.5, hjust = 0.5) +
labs(x = "Semantic Coherence", y = "Exclusivity", title = "Semantic Coherence vs Exclusivity") +
theme_minimal()
rm(stm_model_year)
rm(stm_model_year_16)
stm_model_year_13 <- stm(out$documents, out$vocab, K=13,
prevalence= ~s(pub.year),
data=out$meta, init.type="Spectral",seed=2025,
verbose = F)
# stm_model_year_16 <- stm(out$documents, out$vocab, K=16,
#               prevalence= ~s(pub.year),
#               data=out$meta, init.type="Spectral",seed=2025,
#               verbose = F)
summary(stm_model_year_13)
summary(stm_model_year_13)
summary(stm_model_year_13)
labelTopics(stm_model_year_13, n = 10)
# STM 모델의 theta 매트릭스에서 토픽 비중 추출
topic_matrix <- stm_model_year_13[["theta"]]
# 각 토픽의 평균 비중 계산
average_topic_proportions <- colMeans(topic_matrix)
# 데이터프레임으로 변환
topic_proportions_df <- data.frame(
Topic = paste("Topic", 1:ncol(topic_matrix), sep = " "),
Proportion = average_topic_proportions
)
# 주요 단어 추출 (frex 기준)
topic_labels <- labelTopics(stm_model1, n = 10)$frex
# 데이터프레임에 주요 단어 추가
topic_proportions_df <- topic_proportions_df %>%
mutate(Frex_Top_Words = apply(topic_labels, 1, paste, collapse = ", "))
# STM 모델의 theta 매트릭스에서 토픽 비중 추출
topic_matrix <- stm_model_year_13[["theta"]]
# 각 토픽의 평균 비중 계산
average_topic_proportions <- colMeans(topic_matrix)
# 데이터프레임으로 변환
topic_proportions_df <- data.frame(
Topic = paste("Topic", 1:ncol(topic_matrix), sep = " "),
Proportion = average_topic_proportions
)
# 주요 단어 추출 (frex 기준)
topic_labels <- labelTopics(stm_model_year_13, n = 10)$frex
# 데이터프레임에 주요 단어 추가
topic_proportions_df <- topic_proportions_df %>%
mutate(Frex_Top_Words = apply(topic_labels, 1, paste, collapse = ", "))
# CSV 파일로 저장
write.csv(topic_proportions_df, "topic_proportions.csv", row.names = FALSE)
m1_K <- stm_model_year_13$settings$dim$K
stm_effect_model_year <-  estimateEffect(1:m1_K ~s(pub.year),
stm_model_year_13, meta = out$meta, uncertainty = "Global",prior=1e-5)
summary(stm_effect_model_year, topics= 1:m1_K)
#### 시간에 따른 토픽 비율 변화 (토픽별로)
stm_label_year<- labelTopics(stm_model_year_13, n = 10)
# stm_custom_label <- c('접종순서','거리두기 단계','국내 감염 상황','생활/문화/교육','관련연구/기술',
#                                       '지원정책','관련주','백신 승인','미국 대선','경제 전망','정부/청와대',
#                                       '해외 감염 상황','접종후속대책','변이 바이러스','국제협력','증상/전파','백신/치료제 개발','부작용')
par(mfrow=c(2,2))
j <- 1
for (i in c(1:m1_K))
{
plot(stm_effect_model_year, "year", method = "continuous", topics = i, printlegend = F,
# main = stm_custom_label[j], xaxt = "n")
#main = paste(paste0('T', i,':'),paste(stm_custom_label[i], collapse = ", "),sep=' '),
#xaxt ="n")
# 토픽 이름대신 keyword로 표현하고 싶으면 아래 main 활용
main =  paste('topic', i,paste(stm_label$frex[i,1:4], collapse = ", "),sep=' '))
yearseq <- seq(from=as.Date('2008-01-01'), to=as.Date('2024-12-31'),by='year')
yearnames <- year(yearseq)
axis(1,at=as.numeric(yearseq) - min(as.numeric(yearseq)),labels=yearnames)
j <- j+1
}
#### 시간에 따른 토픽 비율 변화 (토픽별로)
stm_label_year<- labelTopics(stm_model_year_13, n = 10)
# stm_custom_label <- c('접종순서','거리두기 단계','국내 감염 상황','생활/문화/교육','관련연구/기술',
#                                       '지원정책','관련주','백신 승인','미국 대선','경제 전망','정부/청와대',
#                                       '해외 감염 상황','접종후속대책','변이 바이러스','국제협력','증상/전파','백신/치료제 개발','부작용')
par(mfrow=c(2,2))
j <- 1
for (i in c(1:m1_K))
{
plot(stm_effect_model_year, "year", method = "continuous", topics = i, printlegend = F,
# main = stm_custom_label[j], xaxt = "n")
#main = paste(paste0('T', i,':'),paste(stm_custom_label[i], collapse = ", "),sep=' '),
#xaxt ="n")
# 토픽 이름대신 keyword로 표현하고 싶으면 아래 main 활용
main =  paste('topic', i,paste(stm_label$frex[i,1:4], collapse = ", "),sep=' '))
yearseq <- seq(from=as.Date('2008-01-01'), to=as.Date('2024-12-31'),by='year')
yearnames <- year(yearseq)
axis(1,at=as.numeric(yearseq) - min(as.numeric(yearseq)),labels=yearnames)
j <- j+1
}
#### 시간에 따른 토픽 비율 변화 (토픽별로)
stm_label_year<- labelTopics(stm_model_year_13, n = 10)
# stm_custom_label <- c('접종순서','거리두기 단계','국내 감염 상황','생활/문화/교육','관련연구/기술',
#                                       '지원정책','관련주','백신 승인','미국 대선','경제 전망','정부/청와대',
#                                       '해외 감염 상황','접종후속대책','변이 바이러스','국제협력','증상/전파','백신/치료제 개발','부작용')
par(mfrow=c(2,2))
j <- 1
for (i in c(1:m1_K))
{
plot(stm_effect_model_year, "year", method = "continuous", topics = i, printlegend = F,
# main = stm_custom_label[j], xaxt = "n")
#main = paste(paste0('T', i,':'),paste(stm_custom_label[i], collapse = ", "),sep=' '),
#xaxt ="n")
# 토픽 이름대신 keyword로 표현하고 싶으면 아래 main 활용
main =  paste('topic', i,paste(stm_label_year$frex[i,1:4], collapse = ", "),sep=' '))
yearseq <- seq(from=as.Date('2008-01-01'), to=as.Date('2024-12-31'),by='year')
yearnames <- year(yearseq)
axis(1,at=as.numeric(yearseq) - min(as.numeric(yearseq)),labels=yearnames)
j <- j+1
}
#### 시간에 따른 토픽 비율 변화 (토픽별로)
stm_label_year<- labelTopics(stm_model_year_13, n = 10)
# stm_custom_label <- c('접종순서','거리두기 단계','국내 감염 상황','생활/문화/교육','관련연구/기술',
#                                       '지원정책','관련주','백신 승인','미국 대선','경제 전망','정부/청와대',
#                                       '해외 감염 상황','접종후속대책','변이 바이러스','국제협력','증상/전파','백신/치료제 개발','부작용')
par(mfrow=c(2,2))
j <- 1
for (i in c(1:m1_K))
{
plot(stm_effect_model_year, "year", method = "continuous", topics = i, printlegend = F,
# main = stm_custom_label[j], xaxt = "n")
#main = paste(paste0('T', i,':'),paste(stm_custom_label[i], collapse = ", "),sep=' '),
#xaxt ="n")
# 토픽 이름대신 keyword로 표현하고 싶으면 아래 main 활용
main =  paste('topic', i,paste(stm_label_year$frex[i,1:4], collapse = ", "),sep=' '))
yearseq <- seq(from=as.Date('2008-01-01'), to=as.Date('2024-12-31'),by='pub.year')
yearnames <- year(yearseq)
axis(1,at=as.numeric(yearseq) - min(as.numeric(yearseq)),labels=yearnames)
j <- j+1
}
#### 시간에 따른 토픽 비율 변화 (토픽별로)
stm_label_year<- labelTopics(stm_model_year_13, n = 10)
# stm_custom_label <- c('접종순서','거리두기 단계','국내 감염 상황','생활/문화/교육','관련연구/기술',
#                                       '지원정책','관련주','백신 승인','미국 대선','경제 전망','정부/청와대',
#                                       '해외 감염 상황','접종후속대책','변이 바이러스','국제협력','증상/전파','백신/치료제 개발','부작용')
par(mfrow=c(2,2))
j <- 1
for (i in c(1:m1_K))
{
plot(stm_effect_model_year, "pub.year", method = "continuous", topics = i, printlegend = F,
# main = stm_custom_label[j], xaxt = "n")
#main = paste(paste0('T', i,':'),paste(stm_custom_label[i], collapse = ", "),sep=' '),
#xaxt ="n")
# 토픽 이름대신 keyword로 표현하고 싶으면 아래 main 활용
main =  paste('topic', i,paste(stm_label_year$frex[i,1:4], collapse = ", "),sep=' '))
yearseq <- seq(from=as.Date('2008-01-01'), to=as.Date('2024-12-31'),by='pub.year')
yearnames <- year(yearseq)
axis(1,at=as.numeric(yearseq) - min(as.numeric(yearseq)),labels=yearnames)
j <- j+1
}
#### 시간에 따른 토픽 비율 변화 (토픽별로)
stm_label_year<- labelTopics(stm_model_year_13, n = 10)
# stm_custom_label <- c('접종순서','거리두기 단계','국내 감염 상황','생활/문화/교육','관련연구/기술',
#                                       '지원정책','관련주','백신 승인','미국 대선','경제 전망','정부/청와대',
#                                       '해외 감염 상황','접종후속대책','변이 바이러스','국제협력','증상/전파','백신/치료제 개발','부작용')
par(mfrow=c(2,2))
j <- 1
for (i in c(1:m1_K))
{
plot(stm_effect_model_year, "pub.year", method = "continuous", topics = i, printlegend = F,
# main = stm_custom_label[j], xaxt = "n")
#main = paste(paste0('T', i,':'),paste(stm_custom_label[i], collapse = ", "),sep=' '),
#xaxt ="n")
# 토픽 이름대신 keyword로 표현하고 싶으면 아래 main 활용
main =  paste('topic', i,paste(stm_label_year$frex[i,1:4], collapse = ", "),sep=' '))
yearseq <- seq(from=as.Date('2008-01-01'), to=as.Date('2024-12-31'),by='year')
yearnames <- year(yearseq)
axis(1,at=as.numeric(yearseq) - min(as.numeric(yearseq)),labels=yearnames)
j <- j+1
}
# 값이 단일 NaN인지 안전하게 확인하는 함수 정의
is_single_nan <- function(x) {
# 1. x는 원자 단위(atomic)여야 하고,
# 2. 길이가 정확히 1이어야 하며,
# 3. 그 값이 is.nan()이어야 합니다.
# 이 세 조건을 모두 만족하지 않으면 FALSE를 반환하여 오류를 방지합니다.
is.atomic(x) && length(x) == 1 && is.nan(x)
}
# 이제 filter 안에서 새로 정의한 안전한 함수를 사용합니다.
df %>%
filter(map_lgl(kri_num, is_single_nan))
# 값이 단일 NaN인지 안전하게 확인하는 함수 정의
is_single_nan <- function(x) {
# 1. x는 원자 단위(atomic)여야 하고,
# 2. 길이가 정확히 1이어야 하며,
# 3. 그 값이 is.nan()이어야 합니다.
# 이 세 조건을 모두 만족하지 않으면 FALSE를 반환하여 오류를 방지합니다.
is.atomic(x) && length(x) == 1 && is.nan(x)
}
# 이제 filter 안에서 새로 정의한 안전한 함수를 사용합니다.
df %>%
filter(~map_lgl(kri_num, is_single_nan))
# 값이 단일 NaN인지 안전하게 확인하는 함수 정의
is_single_nan <- function(x) {
# 1. x는 원자 단위(atomic)여야 하고,
# 2. 길이가 정확히 1이어야 하며,
# 3. 그 값이 is.nan()이어야 합니다.
# 이 세 조건을 모두 만족하지 않으면 FALSE를 반환하여 오류를 방지합니다.
is.atomic(x) && length(x) == 1 && is.nan(x)
}
# 이제 filter 안에서 새로 정의한 안전한 함수를 사용합니다.
df %>%
filter(!map_lgl(kri_num, is_single_nan))
# 값이 단일 NaN인지 안전하게 확인하는 함수 정의
is_single_nan <- function(x) {
# 1. x는 원자 단위(atomic)여야 하고,
# 2. 길이가 정확히 1이어야 하며,
# 3. 그 값이 is.nan()이어야 합니다.
# 이 세 조건을 모두 만족하지 않으면 FALSE를 반환하여 오류를 방지합니다.
is.atomic(x) && length(x) == 1 && is.nan(x)
}
# 이제 filter 안에서 새로 정의한 안전한 함수를 사용합니다.
df_gender %>%
filter(!map_lgl(kri_num, is_single_nan))
# 값이 단일 NaN인지 안전하게 확인하는 함수 정의
is_single_nan <- function(x) {
# 1. x는 원자 단위(atomic)여야 하고,
# 2. 길이가 정확히 1이어야 하며,
# 3. 그 값이 is.nan()이어야 합니다.
# 이 세 조건을 모두 만족하지 않으면 FALSE를 반환하여 오류를 방지합니다.
is.atomic(x) && length(x) == 1 && is.nan(x)
}
# 이제 filter 안에서 새로 정의한 안전한 함수를 사용합니다.
df_gender <-  df %>%
filter(!map_lgl(kri_num, is_single_nan))
df_gender$gender <- as.factor(df_gender$gender)
View(df_gender)
df_gender$gender <- as.factor(df_gender$gender)
class(df_gender$gender)
df_gender$gender <- as.factor(unlist(df_gender$gender))
print(levels(df_gender$gender))
# 값이 단일 NaN인지 안전하게 확인하는 함수 정의
is_single_nan <- function(x) {
# 1. x는 원자 단위(atomic)여야 하고,
# 2. 길이가 정확히 1이어야 하며,
# 3. 그 값이 is.nan()이어야 합니다.
# 이 세 조건을 모두 만족하지 않으면 FALSE를 반환하여 오류를 방지합니다.
is.atomic(x) && length(x) == 1 && is.nan(x)
}
# 이제 filter 안에서 새로 정의한 안전한 함수를 사용합니다.
df_gender <-  df %>%
filter(!map_lgl(kri_num, is_single_nan))
df_gender$gender <- as.factor(unlist(df_gender$gender))
class(df_gender$gender)
print(levels(df_gender$gender))
# 값이 단일 NaN인지 안전하게 확인하는 함수 정의
is_single_nan <- function(x) {
# 1. x는 원자 단위(atomic)여야 하고,
# 2. 길이가 정확히 1이어야 하며,
# 3. 그 값이 is.nan()이어야 합니다.
# 이 세 조건을 모두 만족하지 않으면 FALSE를 반환하여 오류를 방지합니다.
is.atomic(x) && length(x) == 1 && is.nan(x)
}
# 이제 filter 안에서 새로 정의한 안전한 함수를 사용합니다.
df_gender <-  df %>%
filter(!map_lgl(kri_num, is_single_nan))
print(levels(df_gender$gender))
# 값이 단일 NaN인지 안전하게 확인하는 함수 정의
is_single_nan <- function(x) {
# 1. x는 원자 단위(atomic)여야 하고,
# 2. 길이가 정확히 1이어야 하며,
# 3. 그 값이 is.nan()이어야 합니다.
# 이 세 조건을 모두 만족하지 않으면 FALSE를 반환하여 오류를 방지합니다.
is.atomic(x) && length(x) == 1 && is.nan(x)
}
# 이제 filter 안에서 새로 정의한 안전한 함수를 사용합니다.
df_gender <-  df %>%
filter(!map_lgl(kri_num, is_single_nan))
View(df_gender)
summary(df_gender$gender)
#    이것이 문제를 해결하는 가장 핵심적인 단계입니다.
df_gender$gender <- as.vector(df_gender$gender)
# 2. 이제 깨끗한 벡터가 되었으니, 팩터(factor)로 변환합니다.
df_gender$gender <- as.factor(df_gender$gender)
summary(df_gender$gender)
View(df_gender)
df_gender$gender
#    이것이 문제를 해결하는 가장 핵심적인 단계입니다.
df_gender$gender <- as.vector(df_gender$gender)
# 2. 이제 깨끗한 벡터가 되었으니, 팩터(factor)로 변환합니다.
df_gender$gender <- as.factor(unlist(df_gender$gender))
# 값이 단일 NaN인지 안전하게 확인하는 함수 정의
is_single_nan <- function(x) {
# 1. x는 원자 단위(atomic)여야 하고,
# 2. 길이가 정확히 1이어야 하며,
# 3. 그 값이 is.nan()이어야 합니다.
# 이 세 조건을 모두 만족하지 않으면 FALSE를 반환하여 오류를 방지합니다.
is.atomic(x) && length(x) == 1 && is.nan(x)
}
# 이제 filter 안에서 새로 정의한 안전한 함수를 사용합니다.
df_gender <-  df %>%
filter(!map_lgl(kri_num, is_single_nan))
#    이것이 문제를 해결하는 가장 핵심적인 단계입니다.
df_gender$gender <- as.vector(df_gender$gender)
# 2. 이제 깨끗한 벡터가 되었으니, 팩터(factor)로 변환합니다.
df_gender$gender <- as.factor(unlist(df_gender$gender))
summary(df_gender$gender)
View(df_gender)
# 값이 단일 NaN인지 안전하게 확인하는 함수 정의
is_single_nan <- function(x) {
# 1. x는 원자 단위(atomic)여야 하고,
# 2. 길이가 정확히 1이어야 하며,
# 3. 그 값이 is.nan()이어야 합니다.
# 이 세 조건을 모두 만족하지 않으면 FALSE를 반환하여 오류를 방지합니다.
is.atomic(x) && length(x) == 1 && is.nan(x)
}
# 이제 filter 안에서 새로 정의한 안전한 함수를 사용합니다.
df_gender <-  df %>%
filter(!map_lgl(gender, is_single_nan))
#    이것이 문제를 해결하는 가장 핵심적인 단계입니다.
df_gender$gender <- as.vector(df_gender$gender)
# 2. 이제 깨끗한 벡터가 되었으니, 팩터(factor)로 변환합니다.
df_gender$gender <- as.factor(unlist(df_gender$gender))
df_gender
# 값이 단일 NaN인지 안전하게 확인하는 함수 정의
is_single_nan <- function(x) {
# 1. x는 원자 단위(atomic)여야 하고,
# 2. 길이가 정확히 1이어야 하며,
# 3. 그 값이 is.nan()이어야 합니다.
# 이 세 조건을 모두 만족하지 않으면 FALSE를 반환하여 오류를 방지합니다.
is.atomic(x) && length(x) == 1 && is.nan(x)
}
# 이제 filter 안에서 새로 정의한 안전한 함수를 사용합니다.
df_gender <-  df %>%
filter(!map_lgl(gender, is_single_nan))
# 1. 'gender' 리스트를 안전하게 벡터로 변환합니다.
#    이 코드는 비어있는(NULL) 항목을 NA로 바꾸어 데이터 길이를 그대로 유지합니다.
#    (unlist()는 절대 사용하지 마세요.)
gender_vector <- map_chr(df_gender$gender, ~.x[[1]], .default = NA_character_)
# 1. 'gender' 리스트를 안전하게 벡터로 변환합니다.
#    이 코드는 비어있는(NULL) 항목을 NA로 바꾸어 데이터 길이를 그대로 유지합니다.
#    (unlist()는 절대 사용하지 마세요.)
gender_vector <- map_chr(df_gender$gender, ~.x[[1]], .default = NA_character_)
gender_vector
gender_vector <- map_chr(df_gender$gender, ~.x[[1]], .default = NA_character_)
# 1. 어떤 종류의 비정상 데이터도 NA로 바꾸는 '안전 변환' 함수를 정의합니다.
safe_converter <- function(x) {
# 항목이 NULL이거나, 비어 있거나(list()), 그 안의 첫 값이 NULL인 경우
if (is.null(x) || length(x) == 0 || is.null(x[[1]])) {
return(NA_character_) # 모두 NA로 처리
}
# 첫 번째 값의 길이가 0인 경우 (예: list(character(0)))
if (length(x[[1]]) == 0) {
return(NA_character_) # 이 또한 NA로 처리
}
# 모든 검사를 통과한 정상적인 값이면, 텍스트로 변환하여 반환
return(as.character(x[[1]]))
}
# 2. 새로 만든 'safe_converter' 함수를 map_chr에 적용하여 벡터를 생성합니다.
gender_vector <- map_chr(df_gender$gender, safe_converter)
gender_vector
gender_vector
length(gender_vector)
# 3. 이제 100% 안전한 벡터를 데이터프레임에 다시 할당하고, 팩터(factor)로 변환합니다.
df_gender$gender <- as.factor(gender_vector)
# 4. summary() 함수로 빈도수를 확인합니다.
cat("--- 컬럼 요약 ---\n")
print(summary(df_gender$gender))
df_na_gender <- df_gender %>%
filter(is.na(gender))
print(head(df_na_gender))
# 13021 행의 gender 컬럼에 '남'을 삽입합니다.
df_gender["13021", "gender"] <- "남"
# 13083 행의 gender 컬럼에 '여'를 삽입합니다.
df_gender["13083", "gender"] <- "여"
# 1. 어떤 종류의 비정상 데이터도 NA로 바꾸는 '안전 변환' 함수를 정의합니다.
safe_converter <- function(x) {
# 항목이 NULL이거나, 비어 있거나(list()), 그 안의 첫 값이 NULL인 경우
if (is.null(x) || length(x) == 0 || is.null(x[[1]])) {
return(NA_character_) # 모두 NA로 처리
}
# 첫 번째 값의 길이가 0인 경우 (예: list(character(0)))
if (length(x[[1]]) == 0) {
return(NA_character_) # 이 또한 NA로 처리
}
# 모든 검사를 통과한 정상적인 값이면, 텍스트로 변환하여 반환
return(as.character(x[[1]]))
}
# 2. 새로 만든 'safe_converter' 함수를 map_chr에 적용하여 벡터를 생성합니다.
gender_vector <- map_chr(df_gender$gender, safe_converter)
# 3. 이제 100% 안전한 벡터를 데이터프레임에 다시 할당하고, 팩터(factor)로 변환합니다.
df_gender$gender <- as.factor(gender_vector)
# 4. summary() 함수로 빈도수를 확인합니다.
cat("--- 컬럼 요약 ---\n")
print(summary(df_gender$gender))
myprocess_g <- textProcessor(df_gender$filtered_tokens, metadata = df_gender ,wordLengths=c(1,Inf),lowercase = F,
removenumbers = F, removepunctuation = F, removestopwords = F, stem = F)
myprocess_g
length(myprocess_g$docs.removed)
# N개 이상의 문서에서 등장한 단어만 사용(lower.thresh)
out_g <- prepDocuments(myprocess_g$documents, myprocess_g$vocab, myprocess_g$meta,lower.thresh = 500)
# N개 이상의 문서에서 등장한 단어만 사용(lower.thresh)
out_g <- prepDocuments(myprocess_g$documents, myprocess_g$vocab, myprocess_g$meta,lower.thresh = 400)
model1_searchK_g <- searchK(out_g$documents, out_g$vocab, K = c(4:30),
prevalence = ~gender+s(pub.year),
data = out_g$meta, init.type="Spectral"
,cores=detectCores()-4)
saveRDS(model1_searchK_g,'model1_searchK_g.rds')
plot(model1_searchK_g)
model1_res <- model1_searchK_g$results
model1_res <- unnest(model1_res,c(K,exclus,semcoh))
ggplot(model1_res, aes(x = semcoh, y = exclus, label = K)) +
geom_point() +
geom_text(vjust = -0.5, hjust = 0.5) +
labs(x = "Semantic Coherence", y = "Exclusivity", title = "Semantic Coherence vs Exclusivity") +
theme_minimal()
stm_model_gender_12 <- stm(out_g$documents, out_g$vocab, K=12,
prevalence= ~gender+s(pub.year),
data=out_g$meta, init.type="Spectral",seed=2025,
verbose = F)
labelTopics(stm_model_gender_12, n = 10)
m1_K_g <- stm_model_gender_12$settings$dim$K
stm_effect_model_mf <-  estimateEffect(1:m1_K_g~gender+s(pub.year),
stm_model_gender_12, meta = out_g$meta, uncertainty = "Global",prior=1e-5)
# 명목변수 효과 시각화
plot.estimateEffect(stm_effect_model_gender, covariate = "gender",
topics = c(1:m1_K_g), method = "difference",
model = stm_model_gender_12, # to show labels alongside
cov.value1 = "남", cov.value2 = "여",
xlab = "여 <----------------------> 남", xlim = c(-.4, .4),
labeltype = "frex", n = 10,
width = 100,  verbose.labels = F)
# 명목변수 효과 시각화
plot.estimateEffect(stm_effect_model_gender, covariate = "gender",
topics = c(1:m1_K_g), method = "difference",
model = stm_model_gender_12, # to show labels alongside
cov.value1 = "남", cov.value2 = "여",
xlab = "여 <----------------------> 남", xlim = c(-.4, .4),
labeltype = "frex", n = 10,
width = 100,  verbose.labels = F)
m1_K_g <- stm_model_gender_12$settings$dim$K
stm_effect_model_gender <-  estimateEffect(1:m1_K_g~gender+s(pub.year),
stm_model_gender_12, meta = out_g$meta, uncertainty = "Global",prior=1e-5)
# 명목변수 효과 시각화
plot.estimateEffect(stm_effect_model_gender, covariate = "gender",
topics = c(1:m1_K_g), method = "difference",
model = stm_model_gender_12, # to show labels alongside
cov.value1 = "남", cov.value2 = "여",
xlab = "여 <----------------------> 남", xlim = c(-.4, .4),
labeltype = "frex", n = 10,
width = 100,  verbose.labels = F)
summary(stm_effect_model_gender, topics= 1:m1_K_g)
summary(stm_model_year_13)
# summary(stm_model_year_13)
plot(stm_model_year_13,type='summary',labeltype = 'frex',n=10)
topicCorr(stm_model_year_13, method = "simple", cutoff = 0.05)
correlations <- topicCorr(stm_model_year_13, method = "simple", cutoff = 0.05)
correlations <- topicCorr(stm_model_year_13, method = "simple", cutoff = 0.05)
# Ensure you have the igraph package
library(igraph)
# Plot the network
# The plot function from igraph is automatically used
plot(correlations,
vertex.color = "lightblue",    # Node color
vertex.label.cex = 0.8,        # Node label size
vertex.label.color = "black",  # Node label color
edge.color = "gray80",         # Edge color
main = "STM Topic Correlation Network") # Plot title
install.packages("promises")
library(tidyverse)
library(stm)
library(stminsights)
library(parallel)
library(vroom)
library(reticulate)
py_config()
library(tidyverse)
library(stm)
library(stminsights)
library(parallel)
library(vroom)
library(reticulate)
py_config()
df <- data.frame(py_load_object('./250530_영어영문_토큰화.pkl'))
# 필요한 컬럼만 활용
df <- df %>% select(article.id, pub.year,bigrmas)
# 필요한 컬럼만 활용
df <- df %>% select(article.id, pub.year,bigrams)
df$pub.year <- as.numeric(df$pub.year)
unique_years <- unique(df$pub.year)
print(unique_years)
print(length(unique_years))
# 토큰 리스트->문자열 처리 (for STM)
df$filtered_tokens <- map_chr(df$bigrams,str_c,collapse='  ')
df <- data.frame(py_load_object('./250530_영어영문_토큰화.pkl'))
